{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskma\\AppData\\Local\\Temp\\ipykernel_19508\\1266962817.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"None\", inplace=True)\n",
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.3411 - loss: 2.5236 - val_accuracy: 0.3895 - val_loss: 1.9246\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3960 - loss: 1.8634 - val_accuracy: 0.4158 - val_loss: 1.6565\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.5790 - loss: 1.6379 - val_accuracy: 0.6737 - val_loss: 1.2077\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.7046 - loss: 1.1678 - val_accuracy: 0.7632 - val_loss: 0.9267\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.7841 - loss: 0.8278 - val_accuracy: 0.7947 - val_loss: 0.7378\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.8035 - loss: 0.6815 - val_accuracy: 0.8000 - val_loss: 0.6120\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8258 - loss: 0.5531 - val_accuracy: 0.8684 - val_loss: 0.5329\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.8352 - loss: 0.5134 - val_accuracy: 0.8368 - val_loss: 0.4649\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8754 - loss: 0.3951 - val_accuracy: 0.8737 - val_loss: 0.3865\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.8825 - loss: 0.3473 - val_accuracy: 0.8842 - val_loss: 0.3243\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8896 - loss: 0.3047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
      "Predicted Next Activity: Leucocytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "file_path = \"Sepsis_Merged_Selected_Features_Activity.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Extract activity sequence columns\n",
    "activity_columns = [col for col in df.columns if \"Activity\" in col]\n",
    "df[\"Activity_Sequence\"] = df[activity_columns].apply(lambda row: \" -> \".join(row.values), axis=1)\n",
    "\n",
    "# Encode final activity\n",
    "y = df[\"Final Activity\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Final_Activity_Encoded\"] = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenize activity sequences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(df[\"Activity_Sequence\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Activity_Sequence\"])\n",
    "\n",
    "# Pad sequences to uniform length\n",
    "max_sequence_length = max(map(len, sequences))\n",
    "X_seq = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "y_seq = tf.keras.utils.to_categorical(df[\"Final_Activity_Encoded\"], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=df[\"Final_Activity_Encoded\"])\n",
    "\n",
    "# Define LSTM Model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length),\n",
    "    Masking(mask_value=0.0),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save Model and Tokenizer\n",
    "model.save(\"sepsis_lstm_model.h5\")\n",
    "pd.to_pickle(tokenizer, \"sepsis_tokenizer.pkl\")\n",
    "pd.to_pickle(label_encoder, \"sepsis_label_encoder.pkl\")\n",
    "\n",
    "# Function to Predict Next Activity\n",
    "def predict_next_activity(activity_sequence):\n",
    "    sequence = tokenizer.texts_to_sequences([activity_sequence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    return label_encoder.inverse_transform(predicted_class)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes\"\n",
    "predicted_next_activity = predict_next_activity(example_sequence)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Leucocytes\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Leucocytes\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Leucocytes\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Leucocytes\n"
     ]
    }
   ],
   "source": [
    "print(predict_next_activity(\"ER Registration -> ER Triage -> Leucocytes\"))\n",
    "print(predict_next_activity(\"ER Registration -> ER Triage -> Leucocytes -> LacticAcid\"))\n",
    "print(predict_next_activity(\"ER Registration -> ER Triage -> Leucocytes -> CRP -> IV Antibiotics\"))\n",
    "print(predict_next_activity(\"ER Registration -> ER Triage -> LacticAcid -> DisfuncOrg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskma\\AppData\\Local\\Temp\\ipykernel_19508\\407108260.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"None\", inplace=True)\n",
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.2517 - loss: 2.4046 - val_accuracy: 0.4421 - val_loss: 1.8261\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4362 - loss: 1.7558 - val_accuracy: 0.5316 - val_loss: 1.6171\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5686 - loss: 1.5285 - val_accuracy: 0.6579 - val_loss: 1.1732\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.6931 - loss: 1.0383 - val_accuracy: 0.7684 - val_loss: 0.8464\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7986 - loss: 0.7509 - val_accuracy: 0.7737 - val_loss: 0.7147\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8104 - loss: 0.6291 - val_accuracy: 0.8105 - val_loss: 0.6103\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8390 - loss: 0.5253 - val_accuracy: 0.8526 - val_loss: 0.5401\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8501 - loss: 0.4810 - val_accuracy: 0.8684 - val_loss: 0.4357\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8794 - loss: 0.3597 - val_accuracy: 0.8789 - val_loss: 0.3821\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8950 - loss: 0.3120 - val_accuracy: 0.9053 - val_loss: 0.3245\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9076 - loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "Predicted Next Activity: IV Antibiotics\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking, Input, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "file_path = \"Sepsis_Merged_Selected_Features_Activity.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Extract activity sequence columns\n",
    "activity_columns = [col for col in df.columns if \"Activity\" in col]\n",
    "df[\"Activity_Sequence\"] = df[activity_columns].apply(lambda row: \" -> \".join(row.values), axis=1)\n",
    "\n",
    "# Encode final activity\n",
    "y = df[\"Final Activity\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Final_Activity_Encoded\"] = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenize activity sequences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(df[\"Activity_Sequence\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Activity_Sequence\"])\n",
    "\n",
    "# Pad sequences to uniform length\n",
    "max_sequence_length = max(map(len, sequences))\n",
    "X_seq = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Select numerical features\n",
    "feature_columns = [\n",
    "    \"DiagnosticArtAstrup\", \"DiagnosticUrinarySediment\", \"SIRSCritHeartRate\", \"SIRSCritTachypnea\",\n",
    "    \"SIRSCritTemperature\", \"Hypotensie\", \"SIRSCritLeucos\", \"DiagnosticLacticAcid\", \"Oligurie\",\n",
    "    \"Hypoxie\", \"DisfuncOrg\", \"Infusion\", \"Age\", \"InfectionSuspected\"\n",
    "]\n",
    "X_features = df[feature_columns]\n",
    "\n",
    "# Normalize all numerical features\n",
    "scaler = StandardScaler()\n",
    "X_features = scaler.fit_transform(X_features)\n",
    "\n",
    "y_seq = tf.keras.utils.to_categorical(df[\"Final_Activity_Encoded\"], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Split data\n",
    "X_train_seq, X_test_seq, X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
    "    X_seq, X_features, y_seq, test_size=0.2, random_state=42, stratify=df[\"Final_Activity_Encoded\"]\n",
    ")\n",
    "\n",
    "# Define LSTM Model\n",
    "sequence_input = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length)(sequence_input)\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(masking_layer)\n",
    "\n",
    "# Define Feature Input Model\n",
    "feature_input = Input(shape=(len(feature_columns),))\n",
    "feature_dense = Dense(32, activation='relu')(feature_input)\n",
    "\n",
    "# Merge Sequence and Feature Inputs\n",
    "merged = Concatenate()([lstm_layer, feature_dense])\n",
    "dense_layer = Dense(32, activation='relu')(merged)\n",
    "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n",
    "\n",
    "# Compile Model\n",
    "model = Model(inputs=[sequence_input, feature_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit([X_train_seq, X_train_features], y_train, validation_data=([X_test_seq, X_test_features], y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_accuracy = model.evaluate([X_test_seq, X_test_features], y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save Model and Tokenizer\n",
    "model.save(\"sepsis_lstm_model.h5\")\n",
    "pd.to_pickle(tokenizer, \"sepsis_tokenizer.pkl\")\n",
    "pd.to_pickle(label_encoder, \"sepsis_label_encoder.pkl\")\n",
    "pd.to_pickle(scaler, \"sepsis_scaler.pkl\")\n",
    "\n",
    "# Function to Predict Next Activity\n",
    "def predict_next_activity(activity_sequence, feature_values):\n",
    "    sequence = tokenizer.texts_to_sequences([activity_sequence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    feature_array = np.array(feature_values).reshape(1, -1)\n",
    "    feature_array = scaler.transform(feature_array)\n",
    "    \n",
    "    prediction = model.predict([padded_sequence, feature_array])\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    return label_encoder.inverse_transform(predicted_class)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]  # Example feature values\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioMakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskma\\AppData\\Local\\Temp\\ipykernel_19508\\1578125209.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"None\", inplace=True)\n",
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.2594 - loss: 2.3741 - val_accuracy: 0.3947 - val_loss: 1.8743\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4075 - loss: 1.8071 - val_accuracy: 0.5474 - val_loss: 1.5461\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.6455 - loss: 1.3727 - val_accuracy: 0.7789 - val_loss: 0.9927\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.7764 - loss: 0.9117 - val_accuracy: 0.7842 - val_loss: 0.8457\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8136 - loss: 0.6791 - val_accuracy: 0.8158 - val_loss: 0.6817\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8303 - loss: 0.6218 - val_accuracy: 0.8158 - val_loss: 0.6054\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.8490 - loss: 0.5569 - val_accuracy: 0.8158 - val_loss: 0.5956\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8418 - loss: 0.5100 - val_accuracy: 0.8474 - val_loss: 0.4754\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8704 - loss: 0.4120 - val_accuracy: 0.8947 - val_loss: 0.3933\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8690 - loss: 0.4018 - val_accuracy: 0.9105 - val_loss: 0.3293\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9247 - loss: 0.2893\n",
      "Test Accuracy: 0.91"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Next Activity: ER Triage\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking, Input, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "file_path = \"Sepsis_Merged_Selected_Features_Activity.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df_biomarkers = pd.read_csv(\"Sepsis_Biomarkers_Next_Activity.csv\")\n",
    "\n",
    "df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Extract activity sequence columns\n",
    "activity_columns = [col for col in df.columns if \"Activity\" in col]\n",
    "df[\"Activity_Sequence\"] = df[activity_columns].apply(lambda row: \" -> \".join(row.values), axis=1)\n",
    "\n",
    "# Encode final activity\n",
    "y = df[\"Final Activity\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Final_Activity_Encoded\"] = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenize activity sequences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(df[\"Activity_Sequence\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Activity_Sequence\"])\n",
    "\n",
    "# Pad sequences to uniform length\n",
    "max_sequence_length = max(map(len, sequences))\n",
    "X_seq = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Select numerical features\n",
    "feature_columns = [\n",
    "    \"DiagnosticArtAstrup\", \"DiagnosticUrinarySediment\", \"SIRSCritHeartRate\", \"SIRSCritTachypnea\",\n",
    "    \"SIRSCritTemperature\", \"Hypotensie\", \"SIRSCritLeucos\", \"DiagnosticLacticAcid\", \"Oligurie\",\n",
    "    \"Hypoxie\", \"DisfuncOrg\", \"Infusion\", \"Age\", \"InfectionSuspected\"\n",
    "]\n",
    "X_features = df[feature_columns]\n",
    "\n",
    "# Normalize all numerical features\n",
    "scaler = StandardScaler()\n",
    "X_features = pd.DataFrame(scaler.fit_transform(X_features), columns=feature_columns)\n",
    "\n",
    "y_seq = tf.keras.utils.to_categorical(df[\"Final_Activity_Encoded\"], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Split data\n",
    "X_train_seq, X_test_seq, X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
    "    X_seq, X_features, y_seq, test_size=0.2, random_state=42, stratify=df[\"Final_Activity_Encoded\"]\n",
    ")\n",
    "\n",
    "# Define LSTM Model\n",
    "sequence_input = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length)(sequence_input)\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(masking_layer)\n",
    "\n",
    "# Define Feature Input Model\n",
    "feature_input = Input(shape=(len(feature_columns),))\n",
    "feature_dense = Dense(32, activation='relu')(feature_input)\n",
    "\n",
    "# Merge Sequence and Feature Inputs\n",
    "merged = Concatenate()([lstm_layer, feature_dense])\n",
    "dense_layer = Dense(32, activation='relu')(merged)\n",
    "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n",
    "\n",
    "# Compile Model\n",
    "model = Model(inputs=[sequence_input, feature_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit([X_train_seq, X_train_features], y_train, validation_data=([X_test_seq, X_test_features], y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_accuracy = model.evaluate([X_test_seq, X_test_features], y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save Model and Tokenizer\n",
    "model.save(\"sepsis_lstm_model.h5\")\n",
    "pd.to_pickle(tokenizer, \"sepsis_tokenizer.pkl\")\n",
    "pd.to_pickle(label_encoder, \"sepsis_label_encoder.pkl\")\n",
    "pd.to_pickle(scaler, \"sepsis_scaler.pkl\")\n",
    "\n",
    "# Biomarker-Based Activity Mapping (Prioritized Decision Making)\n",
    "biomarker_priority = [\"LacticAcid\", \"CRP\", \"Leucocytes\"]\n",
    "biomarker_next_activity_mapping = {\n",
    "    \"Leucocytes\": {\"High\": \"LacticAcid\", \"Elevated\": \"CRP\", \"Normal\": \"ER Triage\"},\n",
    "    \"CRP\": {\"Severe\": \"IV Antibiotics\", \"Moderate\": \"LacticAcid\", \"Low\": \"ER Triage\"},\n",
    "    \"LacticAcid\": {\"Critical\": \"ICU Admission\", \"High\": \"IV Fluid\", \"Normal\": \"ER Triage\"}\n",
    "}\n",
    "\n",
    "# Function to Predict Next Activity with Priority-Based Biomarker Handling\n",
    "def predict_next_activity(activity_sequence, feature_values, biomarker_values):\n",
    "    sequence = tokenizer.texts_to_sequences([activity_sequence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    feature_array = np.array(feature_values).reshape(1, -1)\n",
    "    feature_array = scaler.transform(pd.DataFrame(feature_array, columns=feature_columns))\n",
    "    \n",
    "    for biomarker in biomarker_priority:\n",
    "        if biomarker in biomarker_values:\n",
    "            biomarker_value = biomarker_values[biomarker]\n",
    "            if biomarker_value in biomarker_next_activity_mapping[biomarker]:\n",
    "                return biomarker_next_activity_mapping[biomarker][biomarker_value]\n",
    "    \n",
    "    model_prediction = model.predict([padded_sequence, feature_array])\n",
    "    predicted_class = np.argmax(model_prediction, axis=1)\n",
    "    return label_encoder.inverse_transform(predicted_class)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"High\", \"CRP\": \"Severe\", \"LacticAcid\": \"Normal\"}\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ICU Admission\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"High\", \"CRP\": \"Moderate\", \"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 - Predicted Next Activity: ER Triage\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 45, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Normal\", \"CRP\": \"Low\", \"LacticAcid\": \"Normal\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 1 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2 - Predicted Next Activity: LacticAcid\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 55, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Moderate\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 2 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3 - Predicted Next Activity: ICU Admission\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 60, 1]\n",
    "biomarker_values = {\"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 3 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4 - Predicted Next Activity: IV Antibiotics\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65, 1]\n",
    "biomarker_values = {\"CRP\": \"Severe\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 4 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5 - Predicted Next Activity: IV Fluid\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Severe\", \"LacticAcid\": \"High\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 5 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
