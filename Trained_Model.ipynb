{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BioMakers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskma\\AppData\\Local\\Temp\\ipykernel_21472\\1578125209.py:16: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'None' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna(\"None\", inplace=True)\n",
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.2505 - loss: 2.4508 - val_accuracy: 0.4211 - val_loss: 1.8736\n",
      "Epoch 2/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.4290 - loss: 1.8305 - val_accuracy: 0.4421 - val_loss: 1.7168\n",
      "Epoch 3/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5453 - loss: 1.5787 - val_accuracy: 0.7000 - val_loss: 1.1160\n",
      "Epoch 4/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.6766 - loss: 1.1065 - val_accuracy: 0.7632 - val_loss: 0.9103\n",
      "Epoch 5/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.7734 - loss: 0.8449 - val_accuracy: 0.7947 - val_loss: 0.7413\n",
      "Epoch 6/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8007 - loss: 0.6684 - val_accuracy: 0.8053 - val_loss: 0.6703\n",
      "Epoch 7/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8294 - loss: 0.5449 - val_accuracy: 0.8368 - val_loss: 0.5963\n",
      "Epoch 8/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.8279 - loss: 0.5535 - val_accuracy: 0.8579 - val_loss: 0.5478\n",
      "Epoch 9/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8668 - loss: 0.4869 - val_accuracy: 0.8632 - val_loss: 0.4632\n",
      "Epoch 10/10\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.8972 - loss: 0.3835 - val_accuracy: 0.8842 - val_loss: 0.4094\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8989 - loss: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.88\n",
      "Predicted Next Activity: ER Triage\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Masking, Input, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load Data\n",
    "file_path = \"Sepsis_Merged_Selected_Features_Activity.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df_biomarkers = pd.read_csv(\"Sepsis_Biomarkers_Next_Activity.csv\")\n",
    "\n",
    "df.fillna(\"None\", inplace=True)\n",
    "\n",
    "# Extract activity sequence columns\n",
    "activity_columns = [col for col in df.columns if \"Activity\" in col]\n",
    "df[\"Activity_Sequence\"] = df[activity_columns].apply(lambda row: \" -> \".join(row.values), axis=1)\n",
    "\n",
    "# Encode final activity\n",
    "y = df[\"Final Activity\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Final_Activity_Encoded\"] = label_encoder.fit_transform(y)\n",
    "\n",
    "# Tokenize activity sequences\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(df[\"Activity_Sequence\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"Activity_Sequence\"])\n",
    "\n",
    "# Pad sequences to uniform length\n",
    "max_sequence_length = max(map(len, sequences))\n",
    "X_seq = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
    "\n",
    "# Select numerical features\n",
    "feature_columns = [\n",
    "    \"DiagnosticArtAstrup\", \"DiagnosticUrinarySediment\", \"SIRSCritHeartRate\", \"SIRSCritTachypnea\",\n",
    "    \"SIRSCritTemperature\", \"Hypotensie\", \"SIRSCritLeucos\", \"DiagnosticLacticAcid\", \"Oligurie\",\n",
    "    \"Hypoxie\", \"DisfuncOrg\", \"Infusion\", \"Age\", \"InfectionSuspected\"\n",
    "]\n",
    "X_features = df[feature_columns]\n",
    "\n",
    "# Normalize all numerical features\n",
    "scaler = StandardScaler()\n",
    "X_features = pd.DataFrame(scaler.fit_transform(X_features), columns=feature_columns)\n",
    "\n",
    "y_seq = tf.keras.utils.to_categorical(df[\"Final_Activity_Encoded\"], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Split data\n",
    "X_train_seq, X_test_seq, X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
    "    X_seq, X_features, y_seq, test_size=0.2, random_state=42, stratify=df[\"Final_Activity_Encoded\"]\n",
    ")\n",
    "\n",
    "# Define LSTM Model\n",
    "sequence_input = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=64, input_length=max_sequence_length)(sequence_input)\n",
    "masking_layer = Masking(mask_value=0.0)(embedding_layer)\n",
    "lstm_layer = LSTM(64, return_sequences=False)(masking_layer)\n",
    "\n",
    "# Define Feature Input Model\n",
    "feature_input = Input(shape=(len(feature_columns),))\n",
    "feature_dense = Dense(32, activation='relu')(feature_input)\n",
    "\n",
    "# Merge Sequence and Feature Inputs\n",
    "merged = Concatenate()([lstm_layer, feature_dense])\n",
    "dense_layer = Dense(32, activation='relu')(merged)\n",
    "output_layer = Dense(len(label_encoder.classes_), activation='softmax')(dense_layer)\n",
    "\n",
    "# Compile Model\n",
    "model = Model(inputs=[sequence_input, feature_input], outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit([X_train_seq, X_train_features], y_train, validation_data=([X_test_seq, X_test_features], y_test), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate Model\n",
    "test_loss, test_accuracy = model.evaluate([X_test_seq, X_test_features], y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "# Save Model and Tokenizer\n",
    "model.save(\"sepsis_lstm_model.h5\")\n",
    "pd.to_pickle(tokenizer, \"sepsis_tokenizer.pkl\")\n",
    "pd.to_pickle(label_encoder, \"sepsis_label_encoder.pkl\")\n",
    "pd.to_pickle(scaler, \"sepsis_scaler.pkl\")\n",
    "\n",
    "# Biomarker-Based Activity Mapping (Prioritized Decision Making)\n",
    "biomarker_priority = [\"LacticAcid\", \"CRP\", \"Leucocytes\"]\n",
    "biomarker_next_activity_mapping = {\n",
    "    \"Leucocytes\": {\"High\": \"LacticAcid\", \"Elevated\": \"CRP\", \"Normal\": \"ER Triage\"},\n",
    "    \"CRP\": {\"Severe\": \"IV Antibiotics\", \"Moderate\": \"LacticAcid\", \"Low\": \"ER Triage\"},\n",
    "    \"LacticAcid\": {\"Critical\": \"ICU Admission\", \"High\": \"IV Fluid\", \"Normal\": \"ER Triage\"}\n",
    "}\n",
    "\n",
    "# Function to Predict Next Activity with Priority-Based Biomarker Handling\n",
    "def predict_next_activity(activity_sequence, feature_values, biomarker_values):\n",
    "    sequence = tokenizer.texts_to_sequences([activity_sequence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    feature_array = np.array(feature_values).reshape(1, -1)\n",
    "    feature_array = scaler.transform(pd.DataFrame(feature_array, columns=feature_columns))\n",
    "    \n",
    "    for biomarker in biomarker_priority:\n",
    "        if biomarker in biomarker_values:\n",
    "            biomarker_value = biomarker_values[biomarker]\n",
    "            if biomarker_value in biomarker_next_activity_mapping[biomarker]:\n",
    "                return biomarker_next_activity_mapping[biomarker][biomarker_value]\n",
    "    \n",
    "    model_prediction = model.predict([padded_sequence, feature_array])\n",
    "    predicted_class = np.argmax(model_prediction, axis=1)\n",
    "    return label_encoder.inverse_transform(predicted_class)[0]\n",
    "\n",
    "# Example Usage\n",
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"High\", \"CRP\": \"Severe\", \"LacticAcid\": \"Normal\"}\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ICU Admission\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"High\", \"CRP\": \"Moderate\", \"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 - Predicted Next Activity: ER Triage\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 45, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Normal\", \"CRP\": \"Low\", \"LacticAcid\": \"Normal\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 1 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2 - Predicted Next Activity: LacticAcid\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 55, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Moderate\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 2 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3 - Predicted Next Activity: ICU Admission\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 60, 1]\n",
    "biomarker_values = {\"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 3 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4 - Predicted Next Activity: IV Antibiotics\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65, 1]\n",
    "biomarker_values = {\"CRP\": \"Severe\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 4 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5 - Predicted Next Activity: IV Fluid\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Severe\", \"LacticAcid\": \"High\"}\n",
    "\n",
    "predicted_next_activity = predict_next_activity(example_sequence, example_features, biomarker_values)\n",
    "print(f\"Test 5 - Predicted Next Activity: {predicted_next_activity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remaining Time Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskma\\AppData\\Local\\Temp\\ipykernel_21472\\300133237.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_time[\"Complete Timestamp\"] = pd.to_datetime(df_time[\"Complete Timestamp\"], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: IV Fluid, Predicted Remaining Time: 32540.74 seconds (~9.04 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load Data\n",
    "file_path_time = \"Sepsis_Cases_Log.csv\"\n",
    "df_time = pd.read_csv(file_path_time)\n",
    "\n",
    "# Convert timestamps to datetime format\n",
    "df_time[\"Complete Timestamp\"] = pd.to_datetime(df_time[\"Complete Timestamp\"], errors='coerce')\n",
    "df_time = df_time.dropna(subset=[\"Complete Timestamp\"])\n",
    "df_time = df_time.sort_values(by=[\"Case ID\", \"Complete Timestamp\"])\n",
    "\n",
    "# Compute duration between activities within each case\n",
    "df_time[\"Next Timestamp\"] = df_time.groupby(\"Case ID\")[\"Complete Timestamp\"].shift(-1)\n",
    "df_time[\"Activity Duration\"] = (df_time[\"Next Timestamp\"] - df_time[\"Complete Timestamp\"]).dt.total_seconds()\n",
    "df_time[\"Case Start Time\"] = df_time.groupby(\"Case ID\")[\"Complete Timestamp\"].transform(\"first\")\n",
    "df_time[\"Total Case Duration\"] = (df_time[\"Next Timestamp\"] - df_time[\"Case Start Time\"]).dt.total_seconds()\n",
    "df_time = df_time[[\"Case ID\", \"Activity\", \"Activity Duration\", \"Total Case Duration\"]].dropna()\n",
    "\n",
    "# Compute average remaining time per activity\n",
    "df_time_avg = df_time.groupby(\"Activity\")[\"Total Case Duration\"].mean().reset_index()\n",
    "df_time_avg.rename(columns={\"Total Case Duration\": \"Avg Remaining Time\"}, inplace=True)\n",
    "df_time = df_time.merge(df_time_avg, on=\"Activity\", how=\"left\")\n",
    "\n",
    "# Train RandomForest Model for Remaining Time Prediction\n",
    "X_time = df_time[[\"Activity Duration\"]]\n",
    "y_time = df_time[\"Avg Remaining Time\"]\n",
    "X_train_time, X_test_time, y_train_time, y_test_time = train_test_split(X_time, y_time, test_size=0.2, random_state=42)\n",
    "time_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "time_model.fit(X_train_time, y_train_time)\n",
    "\n",
    "# Tokenizer for sequence processing\n",
    "tokenizer = Tokenizer()\n",
    "all_activities = df_time[\"Activity\"].unique().tolist()\n",
    "tokenizer.fit_on_texts(all_activities)\n",
    "max_sequence_length = max([len(tokenizer.texts_to_sequences([a])[0]) for a in all_activities])\n",
    "\n",
    "# Function to Predict Next Activity and Remaining Time\n",
    "def predict_next_activity_and_time(activity_sequence, feature_values, biomarker_values):\n",
    "    # Convert activity sequence to tokenized format\n",
    "    sequence = tokenizer.texts_to_sequences([activity_sequence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length, padding='post')\n",
    "    \n",
    "    # Predict the next activity (this is a placeholder, should be replaced with trained model prediction)\n",
    "    predicted_next_activity = predict_next_activity(activity_sequence, feature_values, biomarker_values)\n",
    "    \n",
    "    # Estimate Activity Duration from Historical Data\n",
    "    if predicted_next_activity in df_time_avg[\"Activity\"].values:\n",
    "        predicted_activity_duration = df_time_avg[df_time_avg[\"Activity\"] == predicted_next_activity][\"Avg Remaining Time\"].values[0]\n",
    "    else:\n",
    "        predicted_activity_duration = 600  # Default to 10 minutes if unknown\n",
    "\n",
    "    # Predict Remaining Time\n",
    "    predicted_remaining_time = time_model.predict([[predicted_activity_duration]])[0]\n",
    "    \n",
    "    return predicted_next_activity, round(predicted_remaining_time, 2)\n",
    "\n",
    "# Example Usage\n",
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Severe\", \"LacticAcid\": \"High\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: IV Antibiotics, Predicted Remaining Time: 47704.86 seconds (~13.25 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 65, 1]\n",
    "biomarker_values = {\"CRP\": \"Severe\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ICU Admission, Predicted Remaining Time: 32540.74 seconds (~9.04 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 60, 1]\n",
    "biomarker_values = {\"LacticAcid\": \"Critical\"}\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ICU Admission, Predicted Remaining Time: 32540.74 seconds (~9.04 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 60, 1]\n",
    "biomarker_values = {\"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: LacticAcid, Predicted Remaining Time: 31062.2 seconds (~8.63 hours)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP\"\n",
    "example_features = [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 55, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Elevated\", \"CRP\": \"Moderate\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ER Triage, Predicted Remaining Time: 13502.19 seconds (~3.75 hours)\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 45, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"Normal\", \"CRP\": \"Low\", \"LacticAcid\": \"Normal\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Code\\GitHub\\Process_Analytics\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Next Activity: ICU Admission, Predicted Remaining Time: 32540.74 seconds (~9.04 hours)\n"
     ]
    }
   ],
   "source": [
    "example_sequence = \"ER Registration -> ER Triage -> Leucocytes -> CRP -> LacticAcid\"\n",
    "example_features = [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 50, 1]\n",
    "biomarker_values = {\"Leucocytes\": \"High\", \"CRP\": \"Moderate\", \"LacticAcid\": \"Critical\"}\n",
    "\n",
    "predicted_next_activity, predicted_remaining_time = predict_next_activity_and_time(example_sequence, example_features, biomarker_values)\n",
    "\n",
    "print(f\"Predicted Next Activity: {predicted_next_activity}, Predicted Remaining Time: {predicted_remaining_time} seconds (~{predicted_remaining_time/3600:.2f} hours)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Save the trained model\n",
    "save_model(model, \"sepsis_lstm_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save tokenizer\n",
    "with open(\"sepsis_tokenizer.pkl\", \"wb\") as file:\n",
    "    pickle.dump(tokenizer, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sepsis_label_encoder.pkl\", \"wb\") as file:\n",
    "    pickle.dump(label_encoder, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sepsis_scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sepsis_time_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(time_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_avg.to_csv(\"Sepsis_Avg_Activity_Duration.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
